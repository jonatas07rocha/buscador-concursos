import requests
from bs4 import BeautifulSoup
import re

# --- CONFIGURAÃ‡ÃƒO DO TESTE ---
# Vamos usar apenas uma URL como nosso "grupo de controle"
URL_CONTROLE = "https://www.pciconcursos.com.br/cargos/psicologo/"

def get_uf_from_string(text: str) -> str:
    """Extrai a sigla do estado (UF) do final de uma string."""
    match = re.search(r'\s-\s([A-Z]{2})$', text.strip())
    if match:
        return match.group(1)
    match_parenteses = re.search(r'\(([A-Z]{2})\)$', text.strip())
    if match_parenteses:
        return match_parenteses.group(1)
    return 'N/D'

def testar_extracao():
    """
    FunÃ§Ã£o de teste que usa a lÃ³gica correta (baseada em .link-d e .link-i)
    para validar a extraÃ§Ã£o de dados.
    """
    print(f"ğŸ•µï¸  Iniciando teste de extraÃ§Ã£o com a lÃ³gica CORRIGIDA:")
    print(f"ğŸ”— URL: {URL_CONTROLE}")
    print("--------------------------------------------------")
    
    vagas_encontradas = []
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(URL_CONTROLE, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'lxml')
        
        # LÃ“GICA CORRETA: Seleciona todos os links de Ã³rgÃ£os e de vagas na ordem
        nodes = soup.select('#pagina .link-d, #pagina .link-i')
        
        print(f"âœ… ConexÃ£o bem-sucedida. {len(nodes)} nÃ³s (Ã³rgÃ£os/vagas) encontrados na pÃ¡gina.")
        print("--------------------------------------------------")

        orgao_atual = "N/A"
        
        for node in nodes:
            # Se o nÃ³ Ã© um Ã³rgÃ£o, atualiza o nome do Ã³rgÃ£o atual
            if 'link-d' in node.get('class', []):
                link_orgao = node.select_one('a')
                if link_orgao and link_orgao.get_text(strip=True):
                    orgao_atual = link_orgao.get_text(strip=True)
            
            # Se o nÃ³ Ã© uma vaga, processa a vaga com o Ãºltimo Ã³rgÃ£o encontrado
            elif 'link-i' in node.get('class', []):
                link_cargo = node.select_one('a')
                if link_cargo:
                    cargo_text = link_cargo.get_text(strip=True)
                    uf = get_uf_from_string(orgao_atual)
                    
                    vaga_data = {
                        'orgao': orgao_atual,
                        'cargo': cargo_text,
                        'uf': uf
                    }
                    vagas_encontradas.append(vaga_data)

    except requests.RequestException as e:
        print(f"âŒ ERRO DE CONEXÃƒO: {e}")
        return
    except Exception as e:
        print(f"âŒ ERRO INESPERADO: {e}")
        return

    # Imprime os resultados encontrados
    if vagas_encontradas:
        print(f"ğŸ‰ SUCESSO! {len(vagas_encontradas)} vagas extraÃ­das:")
        for i, vaga in enumerate(vagas_encontradas[:15], 1): # Mostra as 15 primeiras
            print(f"   {i:02d}. [UF: {vaga['uf']}] {vaga['orgao']} -> Cargo: {vaga['cargo']}")
        if len(vagas_encontradas) > 15:
            print(f"   ... e mais {len(vagas_encontradas) - 15} vagas.")
    else:
        print("ğŸ¤” Nenhuma vaga foi extraÃ­da. A estrutura do site pode ter mudado.")
    
    print("--------------------------------------------------")
    print("Teste finalizado.")

if __name__ == "__main__":
    testar_extracao()
